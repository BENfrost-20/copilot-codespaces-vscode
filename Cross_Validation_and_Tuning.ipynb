{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BENfrost-20/copilot-codespaces-vscode/blob/main/Cross_Validation_and_Tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5i0sMFDr5jO"
      },
      "source": [
        "# **Artificial Neural Networks and Deep Learning**\n",
        "\n",
        "---\n",
        "\n",
        "## **Lecture 3: Cross Validation and Tuning**\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=13uEsx8hOr-fJQ7EtjQgDynZ8QvHuTTBb\" width=\"500\"/>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omSLbdLvhDRx"
      },
      "source": [
        "## 🌐 **Google Drive Connection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3FoTyRa9pLu"
      },
      "source": [
        "## ⚙️ **Libraries Import**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_sOaV1Y8NsL"
      },
      "outputs": [],
      "source": [
        "# Set seed for reproducibility\n",
        "SEED = 42\n",
        "\n",
        "# Import necessary libraries\n",
        "import os\n",
        "\n",
        "# Set environment variables before importing modules\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "os.environ['MPLCONFIGDIR'] = os.getcwd() + '/configs/'\n",
        "\n",
        "# Suppress warnings\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=Warning)\n",
        "\n",
        "# Import necessary modules\n",
        "import logging\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# Set seeds for random number generators in NumPy and Python\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "# Import PyTorch\n",
        "import torch\n",
        "torch.manual_seed(SEED)\n",
        "from torch import nn\n",
        "from torchsummary import summary\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "logs_dir = \"tensorboard\"\n",
        "!pkill -f tensorboard\n",
        "%load_ext tensorboard\n",
        "!mkdir -p models\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"Device: {device}\")\n",
        "\n",
        "# Import other libraries\n",
        "import copy\n",
        "import shutil\n",
        "from itertools import product\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Configure plot display settings\n",
        "sns.set(font_scale=1.4)\n",
        "sns.set_style('white')\n",
        "plt.rc('font', size=14)\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCaGhb5ttXGc"
      },
      "source": [
        "## ⏳ **Data Loading**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxEwCjfpt_6W"
      },
      "outputs": [],
      "source": [
        "# Load the Glass dataset from CSV file\n",
        "os.environ[\"DATASET_NAME\"] = \"glass_dataset.csv\"\n",
        "os.environ[\"DATASET_URL\"] = \"1xyZvjIw2nR5QtlfN9vumuPUjr3SFZLob\"\n",
        "if not os.path.exists(os.environ[\"DATASET_NAME\"]):\n",
        "    print(\"Downloading data...\")\n",
        "    ! gdown -q ${DATASET_URL}\n",
        "    print(\"Download completed\")\n",
        "else:\n",
        "    print(\"Data already downloaded. Using cached data...\")\n",
        "data = pd.read_csv('glass_dataset.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTu9Ca0L1Du2"
      },
      "source": [
        "## 🔎 **Exploration and Data Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P485pmX1uvBf"
      },
      "outputs": [],
      "source": [
        "# Display the first 10 rows of the Glass dataset\n",
        "data.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBZgisH81IK9"
      },
      "outputs": [],
      "source": [
        "# Print the shape of the Glass dataset\n",
        "print('Glass dataset shape', data.shape)\n",
        "\n",
        "# Generate summary statistics for the Glass dataset\n",
        "data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtUiSOuL1liZ"
      },
      "outputs": [],
      "source": [
        "# Get the target values from the Glass dataset\n",
        "target = data['Glass Class'].values\n",
        "print('Target shape', target.shape)\n",
        "\n",
        "# Calculate the unique target labels and their counts\n",
        "unique, count = np.unique(target, return_counts=True)\n",
        "print('Target labels:', unique)\n",
        "for i in range(len(unique)):\n",
        "    print(f'Class {unique[i]} has {count[i]} samples')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_AV2Ce81lf1"
      },
      "outputs": [],
      "source": [
        "# Plot pairwise relationships between features colored by glass class\n",
        "sns.pairplot(\n",
        "    data=data,\n",
        "    hue='Glass Class',\n",
        "    corner=True,        # Display only lower triangle for efficiency\n",
        "    palette='tab10'     # Color palette suitable for 6 classes\n",
        ")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xj6jQOLc33eb"
      },
      "source": [
        "## 🔄 **Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDG_wvir1lc8"
      },
      "outputs": [],
      "source": [
        "# Prepare features and labels as float32 and int64 arrays\n",
        "X = data.drop('Glass Class', axis=1).astype(np.float32).values\n",
        "y = target.astype(np.int64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IxswApXm1lL3"
      },
      "outputs": [],
      "source": [
        "def make_loader(ds, batch_size, shuffle, drop_last):\n",
        "    # Determine optimal number of worker processes for data loading\n",
        "    cpu_cores = os.cpu_count() or 2\n",
        "    num_workers = max(2, min(4, cpu_cores))\n",
        "\n",
        "    # Create DataLoader with performance optimizations\n",
        "    return DataLoader(\n",
        "        ds,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle,\n",
        "        drop_last=drop_last,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=True,  # Faster GPU transfer\n",
        "        pin_memory_device=\"cuda\" if torch.cuda.is_available() else \"\",\n",
        "        prefetch_factor=4,  # Load 4 batches ahead\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yq6ADZrD4xrA"
      },
      "source": [
        "## 🛠️ **Model Building**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJpcWRGb1lDU"
      },
      "outputs": [],
      "source": [
        "# Define a simple feedforward neural network\n",
        "class FeedForwardNet(nn.Module):\n",
        "    def __init__(self, in_features, hidden_layers, hidden_size, dropout_rate, num_classes):\n",
        "        super().__init__()\n",
        "        modules = []\n",
        "        # First layer\n",
        "        modules.append(nn.Linear(in_features, hidden_size))\n",
        "        if dropout_rate > 0 :\n",
        "            modules.append(nn.Dropout(dropout_rate))\n",
        "        modules.append(nn.ReLU())\n",
        "\n",
        "        # Additional hidden layers\n",
        "        for _ in range(hidden_layers):\n",
        "            modules.append(nn.Linear(hidden_size, hidden_size))\n",
        "            if dropout_rate > 0 :\n",
        "                modules.append(nn.Dropout(dropout_rate))\n",
        "            modules.append(nn.ReLU())\n",
        "\n",
        "        # Output layer\n",
        "        modules.append(nn.Linear(hidden_size, num_classes))\n",
        "        self.net = nn.Sequential(*modules)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SeAVVtC47KT"
      },
      "source": [
        "## 🧮 **Network Parameters**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hb7P-CSm4-Jg"
      },
      "source": [
        "## 🧠 **Model Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5yhvl7I1k6f",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title train_one_epoch()\n",
        "def train_one_epoch(model, train_loader, criterion, optimizer, scaler, device, l1_lambda=0, l2_lambda=0):\n",
        "    \"\"\"\n",
        "    Perform one complete training epoch through the entire training dataset.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The neural network model to train\n",
        "        train_loader (DataLoader): PyTorch DataLoader containing training data batches\n",
        "        criterion (nn.Module): Loss function (e.g., CrossEntropyLoss, MSELoss)\n",
        "        optimizer (torch.optim): Optimization algorithm (e.g., Adam, SGD)\n",
        "        scaler (GradScaler): PyTorch's gradient scaler for mixed precision training\n",
        "        device (torch.device): Computing device ('cuda' for GPU, 'cpu' for CPU)\n",
        "        l1_lambda (float): Lambda for L1 regularization\n",
        "        l2_lambda (float): Lambda for L2 regularization\n",
        "\n",
        "    Returns:\n",
        "        tuple: (average_loss, f1 score) - Training loss and f1 score for this epoch\n",
        "    \"\"\"\n",
        "    model.train()  # Set model to training mode\n",
        "\n",
        "    running_loss = 0.0\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "\n",
        "    # Iterate through training batches\n",
        "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "        # Move data to device (GPU/CPU)\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        # Clear gradients from previous step\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        # Forward pass with mixed precision (if CUDA available)\n",
        "        with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n",
        "            logits = model(inputs)\n",
        "            loss = criterion(logits, targets)\n",
        "\n",
        "            # Add L1 and L2 regularization\n",
        "            l1_norm = sum(p.abs().sum() for p in model.parameters())\n",
        "            l2_norm = sum(p.pow(2).sum() for p in model.parameters())\n",
        "            loss = loss + l1_lambda * l1_norm + l2_lambda * l2_norm\n",
        "\n",
        "\n",
        "        # Backward pass with gradient scaling\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        # Accumulate metrics\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        predictions = logits.argmax(dim=1)\n",
        "        all_predictions.append(predictions.cpu().numpy())\n",
        "        all_targets.append(targets.cpu().numpy())\n",
        "\n",
        "    # Calculate epoch metrics\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    epoch_f1 = f1_score(\n",
        "        np.concatenate(all_targets),\n",
        "        np.concatenate(all_predictions),\n",
        "        average='weighted'\n",
        "    )\n",
        "\n",
        "    return epoch_loss, epoch_f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kd-4dZt-1k3n",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title validate_one_epoch()\n",
        "def validate_one_epoch(model, val_loader, criterion, device):\n",
        "    \"\"\"\n",
        "    Perform one complete validation epoch through the entire validation dataset.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The neural network model to evaluate (must be in eval mode)\n",
        "        val_loader (DataLoader): PyTorch DataLoader containing validation data batches\n",
        "        criterion (nn.Module): Loss function used to calculate validation loss\n",
        "        device (torch.device): Computing device ('cuda' for GPU, 'cpu' for CPU)\n",
        "\n",
        "    Returns:\n",
        "        tuple: (average_loss, accuracy) - Validation loss and accuracy for this epoch\n",
        "\n",
        "    Note:\n",
        "        This function automatically sets the model to evaluation mode and disables\n",
        "        gradient computation for efficiency during validation.\n",
        "    \"\"\"\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "\n",
        "    running_loss = 0.0\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "\n",
        "    # Disable gradient computation for validation\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in val_loader:\n",
        "            # Move data to device\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            # Forward pass with mixed precision (if CUDA available)\n",
        "            with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n",
        "                logits = model(inputs)\n",
        "                loss = criterion(logits, targets)\n",
        "\n",
        "            # Accumulate metrics\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            predictions = logits.argmax(dim=1)\n",
        "            all_predictions.append(predictions.cpu().numpy())\n",
        "            all_targets.append(targets.cpu().numpy())\n",
        "\n",
        "    # Calculate epoch metrics\n",
        "    epoch_loss = running_loss / len(val_loader.dataset)\n",
        "    epoch_accuracy = f1_score(\n",
        "        np.concatenate(all_targets),\n",
        "        np.concatenate(all_predictions),\n",
        "        average='weighted'\n",
        "    )\n",
        "\n",
        "    return epoch_loss, epoch_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTSWCMxi1k1H",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title log_metrics_to_tensorboard()\n",
        "def log_metrics_to_tensorboard(writer, epoch, train_loss, train_f1, val_loss, val_f1, model):\n",
        "    \"\"\"\n",
        "    Log training metrics and model parameters to TensorBoard for visualization.\n",
        "\n",
        "    Args:\n",
        "        writer (SummaryWriter): TensorBoard SummaryWriter object for logging\n",
        "        epoch (int): Current epoch number (used as x-axis in TensorBoard plots)\n",
        "        train_loss (float): Training loss for this epoch\n",
        "        train_f1 (float): Training f1 score for this epoch\n",
        "        val_loss (float): Validation loss for this epoch\n",
        "        val_f1 (float): Validation f1 score for this epoch\n",
        "        model (nn.Module): The neural network model (for logging weights/gradients)\n",
        "\n",
        "    Note:\n",
        "        This function logs scalar metrics (loss/f1 score) and histograms of model\n",
        "        parameters and gradients, which helps monitor training progress and detect\n",
        "        issues like vanishing/exploding gradients.\n",
        "    \"\"\"\n",
        "    # Log scalar metrics\n",
        "    writer.add_scalar('Loss/Training', train_loss, epoch)\n",
        "    writer.add_scalar('Loss/Validation', val_loss, epoch)\n",
        "    writer.add_scalar('F1/Training', train_f1, epoch)\n",
        "    writer.add_scalar('F1/Validation', val_f1, epoch)\n",
        "\n",
        "    # Log model parameters and gradients\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            if param.numel() > 0:\n",
        "                writer.add_histogram(f'{name}/weights', param.data, epoch)\n",
        "            if param.grad is not None:\n",
        "                if param.grad.numel() > 0:\n",
        "                    writer.add_histogram(f'{name}/gradients', param.grad.data, epoch)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title fit()\n",
        "def fit(model, train_loader, val_loader, epochs, criterion, optimizer, scaler, device,\n",
        "        l1_lambda=0, l2_lambda=0, patience=0, evaluation_metric=\"val_f1\", mode='max',\n",
        "        restore_best_weights=True, writer=None, verbose=10, experiment_name=\"\"):\n",
        "    \"\"\"\n",
        "    Train the neural network model on the training data and validate on the validation data.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The neural network model to train\n",
        "        train_loader (DataLoader): PyTorch DataLoader containing training data batches\n",
        "        val_loader (DataLoader): PyTorch DataLoader containing validation data batches\n",
        "        epochs (int): Number of training epochs\n",
        "        criterion (nn.Module): Loss function (e.g., CrossEntropyLoss, MSELoss)\n",
        "        optimizer (torch.optim): Optimization algorithm (e.g., Adam, SGD)\n",
        "        scaler (GradScaler): PyTorch's gradient scaler for mixed precision training\n",
        "        device (torch.device): Computing device ('cuda' for GPU, 'cpu' for CPU)\n",
        "        l1_lambda (float): L1 regularization coefficient (default: 0)\n",
        "        l2_lambda (float): L2 regularization coefficient (default: 0)\n",
        "        patience (int): Number of epochs to wait for improvement before early stopping (default: 0)\n",
        "        evaluation_metric (str): Metric to monitor for early stopping (default: \"val_f1\")\n",
        "        mode (str): 'max' for maximizing the metric, 'min' for minimizing (default: 'max')\n",
        "        restore_best_weights (bool): Whether to restore model weights from best epoch (default: True)\n",
        "        writer (SummaryWriter, optional): TensorBoard SummaryWriter object for logging (default: None)\n",
        "        verbose (int, optional): Frequency of printing training progress (default: 10)\n",
        "        experiment_name (str, optional): Experiment name for saving models (default: \"\")\n",
        "\n",
        "    Returns:\n",
        "        tuple: (model, training_history) - Trained model and metrics history\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize metrics tracking\n",
        "    training_history = {\n",
        "        'train_loss': [], 'val_loss': [],\n",
        "        'train_f1': [], 'val_f1': []\n",
        "    }\n",
        "\n",
        "    # Configure early stopping if patience is set\n",
        "    if patience > 0:\n",
        "        patience_counter = 0\n",
        "        best_metric = float('-inf') if mode == 'max' else float('inf')\n",
        "        best_epoch = 0\n",
        "\n",
        "    # Main training loop: iterate through epochs\n",
        "    for epoch in range(1, epochs + 1):\n",
        "\n",
        "        # Forward pass through training data, compute gradients, update weights\n",
        "        train_loss, train_f1 = train_one_epoch(\n",
        "            model, train_loader, criterion, optimizer, scaler, device, l1_lambda, l2_lambda\n",
        "        )\n",
        "\n",
        "        # Evaluate model on validation data without updating weights\n",
        "        val_loss, val_f1 = validate_one_epoch(\n",
        "            model, val_loader, criterion, device\n",
        "        )\n",
        "\n",
        "        # Store metrics for plotting and analysis\n",
        "        training_history['train_loss'].append(train_loss)\n",
        "        training_history['val_loss'].append(val_loss)\n",
        "        training_history['train_f1'].append(train_f1)\n",
        "        training_history['val_f1'].append(val_f1)\n",
        "\n",
        "        # Write metrics to TensorBoard for visualization\n",
        "        if writer is not None:\n",
        "            log_metrics_to_tensorboard(\n",
        "                writer, epoch, train_loss, train_f1, val_loss, val_f1, model\n",
        "            )\n",
        "\n",
        "        # Print progress every N epochs or on first epoch\n",
        "        if verbose > 0:\n",
        "            if epoch % verbose == 0 or epoch == 1:\n",
        "                print(f\"Epoch {epoch:3d}/{epochs} | \"\n",
        "                    f\"Train: Loss={train_loss:.4f}, F1 Score={train_f1:.4f} | \"\n",
        "                    f\"Val: Loss={val_loss:.4f}, F1 Score={val_f1:.4f}\")\n",
        "\n",
        "        # Early stopping logic: monitor metric and save best model\n",
        "        if patience > 0:\n",
        "            current_metric = training_history[evaluation_metric][-1]\n",
        "            is_improvement = (current_metric > best_metric) if mode == 'max' else (current_metric < best_metric)\n",
        "\n",
        "            if is_improvement:\n",
        "                best_metric = current_metric\n",
        "                best_epoch = epoch\n",
        "                torch.save(model.state_dict(), \"models/\"+experiment_name+'_model.pt')\n",
        "                patience_counter = 0\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "                if patience_counter >= patience:\n",
        "                    if verbose > 0:\n",
        "                        print(f\"Early stopping triggered after {epoch} epochs.\")\n",
        "                    break\n",
        "\n",
        "    # Restore best model weights if early stopping was used\n",
        "    if restore_best_weights and patience > 0:\n",
        "        model.load_state_dict(torch.load(\"models/\"+experiment_name+'_model.pt'))\n",
        "        if verbose > 0:\n",
        "            print(f\"Best model restored from epoch {best_epoch} with {evaluation_metric} {best_metric:.4f}\")\n",
        "\n",
        "    # Save final model if no early stopping\n",
        "    if patience == 0:\n",
        "        torch.save(model.state_dict(), \"models/\"+experiment_name+'_model.pt')\n",
        "\n",
        "    # Close TensorBoard writer\n",
        "    if writer is not None:\n",
        "        writer.close()\n",
        "\n",
        "    return model, training_history"
      ],
      "metadata": {
        "id": "u7OpSai1FNPU",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def k_shuffle_split_cross_validation_round(X, y, epochs, criterion, scaler, device,\n",
        "                            k, test_size, batch_size, hidden_layers, hidden_size, learning_rate, dropout_rate,\n",
        "                            l1_lambda=0, l2_lambda=0, patience=0, evaluation_metric=\"val_f1\", mode='max',\n",
        "                            restore_best_weights=True, writer=None, verbose=10, seed=SEED, experiment_name=\"\"):\n",
        "\n",
        "    # Initialise containers for results across all splits\n",
        "    fold_losses = {}\n",
        "    fold_metrics = {}\n",
        "    best_scores = {}\n",
        "\n",
        "    # Initialise model architecture\n",
        "    in_features = X.shape[1]\n",
        "    num_classes = len(np.unique(y))\n",
        "    model = FeedForwardNet(in_features, hidden_layers=hidden_layers, hidden_size=hidden_size,\n",
        "                           dropout_rate=dropout_rate, num_classes=num_classes).to(device)\n",
        "\n",
        "    # Store initial weights to reset model for each split\n",
        "    initial_state = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    # Iterate through K random splits\n",
        "    for split_idx in range(k):\n",
        "\n",
        "        if verbose > 0:\n",
        "            print(f\"Split {split_idx+1}/{k}\")\n",
        "\n",
        "        # Create train-val-test split with stratification\n",
        "        X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
        "            X, y,\n",
        "            test_size=test_size,\n",
        "            random_state=SEED+split_idx,\n",
        "            stratify=y\n",
        "        )\n",
        "        X_train, X_val, y_train, y_val = train_test_split(\n",
        "            X_train_val, y_train_val,\n",
        "            test_size=test_size,\n",
        "            random_state=SEED+split_idx,\n",
        "            stratify=y_train_val\n",
        "        )\n",
        "\n",
        "        # Normalise features using training set statistics\n",
        "        train_max = X_train.max(axis=0)\n",
        "        train_min = X_train.min(axis=0)\n",
        "        X_train = (X_train - train_min) / (train_max - train_min + 1e-8)\n",
        "        X_val = (X_val - train_min) / (train_max - train_min + 1e-8)\n",
        "        X_test = (X_test - train_min) / (train_max - train_min + 1e-8)\n",
        "\n",
        "        # Create PyTorch datasets\n",
        "        train_ds = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
        "        val_ds   = TensorDataset(torch.from_numpy(X_val), torch.from_numpy(y_val))\n",
        "        test_ds  = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\n",
        "\n",
        "        # Create data loaders\n",
        "        train_loader = make_loader(train_ds, batch_size=batch_size, shuffle=True, drop_last=False)\n",
        "        val_loader   = make_loader(val_ds, batch_size=batch_size, shuffle=False, drop_last=False)\n",
        "        test_loader  = make_loader(test_ds, batch_size=batch_size, shuffle=False, drop_last=False)\n",
        "\n",
        "        # Reset model to initial weights for fair comparison across splits\n",
        "        model.load_state_dict(initial_state)\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=l2_lambda)\n",
        "\n",
        "        # Create directory for model checkpoints\n",
        "        !mkdir -p models/{experiment_name}\n",
        "\n",
        "        # Train model on current split\n",
        "        model, training_history = fit(\n",
        "            model=model,\n",
        "            train_loader=train_loader,\n",
        "            val_loader=val_loader,\n",
        "            epochs=epochs,\n",
        "            criterion=criterion,\n",
        "            optimizer=optimizer,\n",
        "            scaler=scaler,\n",
        "            device=device,\n",
        "            writer=writer,\n",
        "            patience=patience,\n",
        "            verbose=verbose,\n",
        "            experiment_name=experiment_name+\"/split_\"+str(split_idx)\n",
        "        )\n",
        "\n",
        "        # Store results for this split\n",
        "        fold_losses[f\"split_{split_idx}\"] = training_history['val_loss']\n",
        "        fold_metrics[f\"split_{split_idx}\"] = training_history['val_f1']\n",
        "        best_scores[f\"split_{split_idx}\"] = max(training_history['val_f1'])\n",
        "\n",
        "    # Compute mean and standard deviation of best scores across splits\n",
        "    best_scores[\"mean\"] = np.mean([best_scores[k] for k in best_scores.keys()])\n",
        "    best_scores[\"std\"] = np.std([best_scores[k] for k in best_scores.keys()])\n",
        "\n",
        "    if verbose > 0:\n",
        "        print(f\"Best score: {best_scores['mean']:.4f}±{best_scores['std']:.4f}\")\n",
        "\n",
        "    return fold_losses, fold_metrics, best_scores"
      ],
      "metadata": {
        "id": "k5FFBYRpU1TV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross-validation\n",
        "K = 5                    # Number of splits (5 and 10 are considered good values)\n",
        "TEST_SIZE = 0.2          # Validation/test proportion\n",
        "\n",
        "# Training\n",
        "EPOCHS = 100              # Maximum epochs (increase to improve performance)\n",
        "PATIENCE = 20             # Early stopping patience (increase to improve performance)\n",
        "VERBOSE = 10             # Print frequency\n",
        "\n",
        "# Optimisation\n",
        "LEARNING_RATE = 1e-3     # Learning rate\n",
        "BATCH_SIZE = 64          # Batch size\n",
        "\n",
        "# Architecture\n",
        "HIDDEN_LAYERS = 2        # Hidden layers\n",
        "HIDDEN_SIZE = 128        # Neurons per layer\n",
        "\n",
        "# Regularisation\n",
        "DROPOUT_RATE = 0         # Dropout probability\n",
        "L1_LAMBDA = 0            # L1 penalty\n",
        "L2_LAMBDA = 0            # L2 penalty\n",
        "\n",
        "# Training utilities\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=(device.type == 'cuda'))\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "4wevD9tXhc8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Baseline**"
      ],
      "metadata": {
        "id": "E5fY9uFixhZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Execute K-fold cross-validation with baseline configuration\n",
        "losses, metrics, best_scores = k_shuffle_split_cross_validation_round(\n",
        "    X=X,\n",
        "    y=y,\n",
        "    epochs=EPOCHS,\n",
        "    criterion=criterion,\n",
        "    scaler=scaler,\n",
        "    device=device,\n",
        "    k=K,\n",
        "    test_size=TEST_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    hidden_layers=HIDDEN_LAYERS,\n",
        "    hidden_size=HIDDEN_SIZE,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    dropout_rate=DROPOUT_RATE,\n",
        "    l1_lambda=L1_LAMBDA,\n",
        "    l2_lambda=L2_LAMBDA,\n",
        "    verbose=VERBOSE,\n",
        "    patience=PATIENCE,\n",
        "    seed=SEED,\n",
        "    experiment_name=\"baseline\"\n",
        ")"
      ],
      "metadata": {
        "id": "2NnrW7Krsaqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Plot Hitory\n",
        "# Create figure with two subplots sharing x axis\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(18, 5), sharex=True)\n",
        "\n",
        "# Color palette for K splits\n",
        "colors = plt.cm.get_cmap('tab10', K)\n",
        "\n",
        "# Plot validation loss for each split\n",
        "for split in range(K):\n",
        "    axes[0].plot(losses[f'split_{split}'][:-PATIENCE], label=f'Split {split+1}',\n",
        "                 color=colors(split), alpha=0.6)\n",
        "axes[0].set_title('Validation Loss per Split')\n",
        "axes[0].set_ylabel('Loss')\n",
        "axes[0].set_xlabel('Epoch')\n",
        "axes[0].grid(alpha=0.3)\n",
        "\n",
        "# Plot validation F1 score for each split\n",
        "for split in range(K):\n",
        "    axes[1].plot(metrics[f'split_{split}'][:-PATIENCE], label=f'Split {split+1}',\n",
        "                 color=colors(split), alpha=0.6)\n",
        "axes[1].set_title('Validation F1 Score per Split')\n",
        "axes[1].set_ylabel('F1 Score')\n",
        "axes[1].set_xlabel('Epoch')\n",
        "axes[1].grid(alpha=0.3)\n",
        "\n",
        "# Add shared legend on the right\n",
        "handles, labels = axes[0].get_legend_handles_labels()\n",
        "fig.legend(handles, labels, loc='center left', bbox_to_anchor=(1, 0.5), fontsize='small')\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "plt.subplots_adjust(right=0.975)\n",
        "plt.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "dYU3mTMfFrxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Hyperparameters Tuning**"
      ],
      "metadata": {
        "id": "ybJgNcvXOCFu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def grid_search_cv(X, y, param_grid, fixed_params, cv_params, verbose=True):\n",
        "    \"\"\"\n",
        "    Execute grid search with K-fold cross-validation.\n",
        "\n",
        "    Args:\n",
        "        X, y: Training data and labels\n",
        "        param_grid: Dict of parameters to test, e.g. {'batch_size': [16, 32, 64]}\n",
        "        fixed_params: Dict of fixed hyperparameters (hidden_size, learning_rate, etc.)\n",
        "        cv_params: Dict of CV settings (epochs, k, patience, criterion, scaler, device, etc.)\n",
        "        verbose: Print progress for each configuration\n",
        "\n",
        "    Returns:\n",
        "        results: Dict with scores for each configuration\n",
        "        best_config: Dict with best hyperparameter combination\n",
        "        best_score: Best mean F1 score achieved\n",
        "    \"\"\"\n",
        "    from itertools import product\n",
        "\n",
        "    # Generate all parameter combinations\n",
        "    param_names = list(param_grid.keys())\n",
        "    param_values = list(param_grid.values())\n",
        "    combinations = list(product(*param_values))\n",
        "\n",
        "    results = {}\n",
        "    best_score = -np.inf\n",
        "    best_config = None\n",
        "\n",
        "    total = len(combinations)\n",
        "\n",
        "    for idx, combo in enumerate(combinations, 1):\n",
        "        # Create current configuration dict\n",
        "        current_config = dict(zip(param_names, combo))\n",
        "        config_str = \"_\".join([f\"{k}_{v}\" for k, v in current_config.items()])\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"\\nConfiguration {idx}/{total}:\")\n",
        "            for param, value in current_config.items():\n",
        "                print(f\"  {param}: {value}\")\n",
        "\n",
        "        # Merge current config with fixed parameters\n",
        "        run_params = {**fixed_params, **current_config}\n",
        "\n",
        "        # Execute cross-validation\n",
        "        _, _, fold_scores = k_shuffle_split_cross_validation_round(\n",
        "            X=X, y=y,\n",
        "            experiment_name=config_str,\n",
        "            **run_params,\n",
        "            **cv_params\n",
        "        )\n",
        "\n",
        "        # Store results\n",
        "        results[config_str] = fold_scores\n",
        "\n",
        "        # Track best configuration\n",
        "        if fold_scores[\"mean\"] > best_score:\n",
        "            best_score = fold_scores[\"mean\"]\n",
        "            best_config = current_config.copy()\n",
        "            if verbose:\n",
        "                print(\"  NEW BEST SCORE!\")\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"  F1 Score: {fold_scores['mean']:.4f}±{fold_scores['std']:.4f}\")\n",
        "\n",
        "    return results, best_config, best_score\n",
        "\n",
        "\n",
        "def plot_top_configurations(results, k_splits, top_n=5, figsize=(12, 6)):\n",
        "    \"\"\"\n",
        "    Visualise top N configurations with boxplots of F1 scores across CV splits.\n",
        "\n",
        "    Args:\n",
        "        results: Dict of results from grid_search_cv\n",
        "        k_splits: Number of CV splits used\n",
        "        top_n: Number of top configurations to display\n",
        "        figsize: Figure size tuple\n",
        "    \"\"\"\n",
        "    # Sort by mean score\n",
        "    config_scores = {name: data['mean'] for name, data in results.items()}\n",
        "    sorted_configs = sorted(config_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Select top N\n",
        "    top_configs = sorted_configs[:min(top_n, len(sorted_configs))]\n",
        "\n",
        "    # Prepare boxplot data\n",
        "    boxplot_data = []\n",
        "    labels = []\n",
        "\n",
        "    # Define a dictionary for replacements, ordered to handle prefixes correctly\n",
        "    replacements = {\n",
        "        'batch_size_': 'BS=',\n",
        "        'learning_rate_': '\\nLR=',\n",
        "        'hidden_layers_': '\\nHL=',\n",
        "        'hidden_size_': '\\nHS=',\n",
        "        'dropout_rate_': '\\nDR=',\n",
        "        'l1_lambda_': '\\nL1=',\n",
        "        'l2_lambda_': '\\nL2='\n",
        "    }\n",
        "\n",
        "    # Replacements for separators\n",
        "    separator_replacements = {\n",
        "        '_learning_rate_': '\\nLR=',\n",
        "        '_hidden_layers_': '\\nHL=',\n",
        "        '_hidden_size_': '\\nHS=',\n",
        "        '_dropout_rate_': '\\nDR=',\n",
        "        '_l1_lambda_': '\\nL1=',\n",
        "        '_l2_lambda_': '\\nL2=',\n",
        "        '_': ''\n",
        "    }\n",
        "\n",
        "\n",
        "    for config_name, mean_score in top_configs:\n",
        "        # Extract best score from each split (auto-detect number of splits)\n",
        "        split_scores = []\n",
        "        for i in range(k_splits):\n",
        "            if f'split_{i}' in results[config_name]:\n",
        "                split_scores.append(results[config_name][f'split_{i}'])\n",
        "        boxplot_data.append(split_scores)\n",
        "\n",
        "        # Verify we have the expected number of splits\n",
        "        if len(split_scores) != k_splits:\n",
        "            print(f\"Warning: Config {config_name} has {len(split_scores)} splits, expected {k_splits}\")\n",
        "\n",
        "        # Create readable label using the replacements dictionary\n",
        "        readable_label = config_name\n",
        "        for old, new in replacements.items():\n",
        "            readable_label = readable_label.replace(old, new)\n",
        "\n",
        "        # Apply separator replacements\n",
        "        for old, new in separator_replacements.items():\n",
        "             readable_label = readable_label.replace(old, new)\n",
        "\n",
        "        labels.append(f\"{readable_label}\\n(μ={mean_score:.3f})\")\n",
        "\n",
        "    # Create plot\n",
        "    fig, ax = plt.subplots(figsize=figsize)\n",
        "    bp = ax.boxplot(boxplot_data, labels=labels, patch_artist=True,\n",
        "                    showmeans=True, meanline=True)\n",
        "\n",
        "    # Styling\n",
        "    for patch in bp['boxes']:\n",
        "        patch.set_facecolor('lightblue')\n",
        "        patch.set_alpha(0.7)\n",
        "\n",
        "    # Highlight best configuration\n",
        "    ax.get_xticklabels()[0].set_fontweight('bold')\n",
        "\n",
        "    ax.set_ylabel('F1 Score')\n",
        "    ax.set_xlabel('Configuration')\n",
        "    ax.set_title(f'Top {len(top_configs)} Configurations - F1 Score Distribution Across {k_splits} Splits')\n",
        "    ax.grid(alpha=0.3, axis='y')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "MK8jVnuI2Sld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VERBOSE = 0             # Print frequency"
      ],
      "metadata": {
        "id": "c31PEutsF4-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Batch Size**"
      ],
      "metadata": {
        "id": "IjA-9Cosexji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Define parameters to search\n",
        "param_grid = {\n",
        "    'batch_size': [4, 16, 32, 64, 128]\n",
        "}\n",
        "\n",
        "# Fixed hyperparameters (not being tuned)\n",
        "fixed_params = {\n",
        "    'hidden_layers': HIDDEN_LAYERS,\n",
        "    'hidden_size': HIDDEN_SIZE,\n",
        "    'learning_rate': LEARNING_RATE,\n",
        "    'dropout_rate': DROPOUT_RATE,\n",
        "    'l1_lambda': L1_LAMBDA,\n",
        "    'l2_lambda': L2_LAMBDA\n",
        "}\n",
        "\n",
        "# Cross-validation settings\n",
        "cv_params = {\n",
        "    'epochs': EPOCHS,\n",
        "    'criterion': criterion,\n",
        "    'scaler': scaler,\n",
        "    'device': device,\n",
        "    'k': K,\n",
        "    'test_size': TEST_SIZE,\n",
        "    'patience': PATIENCE,\n",
        "    'verbose': VERBOSE,\n",
        "    'seed': SEED\n",
        "}\n",
        "\n",
        "# Execute search\n",
        "results, best_config, best_score = grid_search_cv(\n",
        "    X=X, y=y,\n",
        "    param_grid=param_grid,\n",
        "    fixed_params=fixed_params,\n",
        "    cv_params=cv_params\n",
        ")"
      ],
      "metadata": {
        "id": "xGs5tr8H2bwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the results\n",
        "print(results)"
      ],
      "metadata": {
        "id": "iuY_U3gi7hrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the best configuration found\n",
        "print(best_config)"
      ],
      "metadata": {
        "id": "RRTtTsIu7iJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the best performance achieved\n",
        "print(best_score)"
      ],
      "metadata": {
        "id": "Xy174JO77iG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualise results\n",
        "plot_top_configurations(results, k_splits=K, top_n=5)"
      ],
      "metadata": {
        "id": "A9-Ixz-76A80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Learning Rate**"
      ],
      "metadata": {
        "id": "FMqSO8bxBORl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Define parameters to search\n",
        "param_grid = {\n",
        "    'learning_rate': [1e-4, 5e-4, 1e-3, 5e-3, 1e-2]\n",
        "}\n",
        "\n",
        "# Fixed hyperparameters (not being tuned)\n",
        "fixed_params = {\n",
        "    'hidden_layers': HIDDEN_LAYERS,\n",
        "    'hidden_size': HIDDEN_SIZE,\n",
        "    'batch_size': BATCH_SIZE,\n",
        "    'dropout_rate': DROPOUT_RATE,\n",
        "    'l1_lambda': L1_LAMBDA,\n",
        "    'l2_lambda': L2_LAMBDA\n",
        "}\n",
        "\n",
        "# Cross-validation settings\n",
        "cv_params = {\n",
        "    'epochs': EPOCHS,\n",
        "    'criterion': criterion,\n",
        "    'scaler': scaler,\n",
        "    'device': device,\n",
        "    'k': K,\n",
        "    'test_size': TEST_SIZE,\n",
        "    'patience': PATIENCE,\n",
        "    'verbose': VERBOSE,\n",
        "    'seed': SEED\n",
        "}\n",
        "\n",
        "# Execute search\n",
        "results, best_config, best_score = grid_search_cv(\n",
        "    X=X, y=y,\n",
        "    param_grid=param_grid,\n",
        "    fixed_params=fixed_params,\n",
        "    cv_params=cv_params\n",
        ")"
      ],
      "metadata": {
        "id": "UINFAFWm7ROa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualise results\n",
        "plot_top_configurations(results, k_splits=K, top_n=4)"
      ],
      "metadata": {
        "id": "g1sA096B9c4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model Complexity**"
      ],
      "metadata": {
        "id": "1sQAQ6k90DDv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Define parameters to search\n",
        "param_grid = {\n",
        "    'hidden_layers': [1, 2],\n",
        "    'hidden_size': [32, 128, 512]\n",
        "}\n",
        "\n",
        "# Fixed hyperparameters (not being tuned)\n",
        "fixed_params = {\n",
        "    'learning_rate': LEARNING_RATE,\n",
        "    'batch_size': BATCH_SIZE,\n",
        "    'dropout_rate': DROPOUT_RATE,\n",
        "    'l1_lambda': L1_LAMBDA,\n",
        "    'l2_lambda': L2_LAMBDA\n",
        "}\n",
        "\n",
        "# Cross-validation settings\n",
        "cv_params = {\n",
        "    'epochs': EPOCHS,\n",
        "    'criterion': criterion,\n",
        "    'scaler': scaler,\n",
        "    'device': device,\n",
        "    'k': K,\n",
        "    'test_size': TEST_SIZE,\n",
        "    'patience': PATIENCE,\n",
        "    'verbose': VERBOSE,\n",
        "    'seed': SEED\n",
        "}\n",
        "\n",
        "# Execute search\n",
        "results, best_config, best_score = grid_search_cv(\n",
        "    X=X, y=y,\n",
        "    param_grid=param_grid,\n",
        "    fixed_params=fixed_params,\n",
        "    cv_params=cv_params\n",
        ")"
      ],
      "metadata": {
        "id": "d3Need769uyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualise results\n",
        "plot_top_configurations(results, k_splits=K, top_n=3)"
      ],
      "metadata": {
        "id": "4DEIcs2I9uwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Batch Size vs Learning Rate vs Model Complexity**"
      ],
      "metadata": {
        "id": "9x2oKpcfftDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Define parameters to search\n",
        "param_grid = {\n",
        "    'batch_size': [16, 32],\n",
        "    'learning_rate': [1e-3, 5e-3],\n",
        "    'hidden_layers': [1, 2],\n",
        "    'hidden_size': [128, 512]\n",
        "}\n",
        "\n",
        "# Fixed hyperparameters (not being tuned)\n",
        "fixed_params = {\n",
        "    'dropout_rate': DROPOUT_RATE,\n",
        "    'l1_lambda': L1_LAMBDA,\n",
        "    'l2_lambda': L2_LAMBDA\n",
        "}\n",
        "\n",
        "# Cross-validation settings\n",
        "cv_params = {\n",
        "    'epochs': EPOCHS,\n",
        "    'criterion': criterion,\n",
        "    'scaler': scaler,\n",
        "    'device': device,\n",
        "    'k': K,\n",
        "    'test_size': TEST_SIZE,\n",
        "    'patience': PATIENCE,\n",
        "    'verbose': VERBOSE,\n",
        "    'seed': SEED\n",
        "}\n",
        "\n",
        "# Execute search\n",
        "results, best_config, best_score = grid_search_cv(\n",
        "    X=X, y=y,\n",
        "    param_grid=param_grid,\n",
        "    fixed_params=fixed_params,\n",
        "    cv_params=cv_params\n",
        ")"
      ],
      "metadata": {
        "id": "9Ic-gTJO-Wtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualise results\n",
        "plot_top_configurations(results, k_splits=K, top_n=5)"
      ],
      "metadata": {
        "id": "nhPhkunT-Wog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model Regularisation**\n",
        "\n"
      ],
      "metadata": {
        "id": "l8i8yY-88bvK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Define parameters to search\n",
        "param_grid = {\n",
        "    'dropout_rate': [0, 0.2, 0.5],\n",
        "    'l1_lambda': [0, 1e-4, 1e-2],\n",
        "    'l2_lambda': [0, 1e-4, 1e-2]\n",
        "}\n",
        "\n",
        "# Fixed hyperparameters (not being tuned)\n",
        "fixed_params = {\n",
        "    'batch_size': 16,\n",
        "    'learning_rate': 0.005,\n",
        "    'hidden_layers': 2,\n",
        "    'hidden_size': 512\n",
        "}\n",
        "\n",
        "# Cross-validation settings\n",
        "cv_params = {\n",
        "    'epochs': EPOCHS,\n",
        "    'criterion': criterion,\n",
        "    'scaler': scaler,\n",
        "    'device': device,\n",
        "    'k': K,\n",
        "    'test_size': TEST_SIZE,\n",
        "    'patience': PATIENCE,\n",
        "    'verbose': VERBOSE,\n",
        "    'seed': SEED\n",
        "}\n",
        "\n",
        "# Execute search\n",
        "results, best_config, best_score = grid_search_cv(\n",
        "    X=X, y=y,\n",
        "    param_grid=param_grid,\n",
        "    fixed_params=fixed_params,\n",
        "    cv_params=cv_params\n",
        ")"
      ],
      "metadata": {
        "id": "bkLafrp1DMoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualise results\n",
        "plot_top_configurations(results, k_splits=K, top_n=5)"
      ],
      "metadata": {
        "id": "Zt724GBUDMlV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Batch Size vs Learning Rate vs Model Complexity vs Model Regularisation**"
      ],
      "metadata": {
        "id": "0nf4YT8m-vFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Define parameters to search\n",
        "param_grid = {\n",
        "    'batch_size': [16, 32],\n",
        "    'learning_rate': [1e-3, 5e-3],\n",
        "    'hidden_layers': [1, 2],\n",
        "    'hidden_size': [128, 512],\n",
        "    'dropout_rate': [0, 0.2, 0.5],\n",
        "    'l1_lambda': [0, 1e-4, 1e-2],\n",
        "    'l2_lambda': [0, 1e-4, 1e-2]\n",
        "}\n",
        "\n",
        "# Fixed hyperparameters (not being tuned)\n",
        "fixed_params = {}\n",
        "\n",
        "# Cross-validation settings\n",
        "cv_params = {\n",
        "    'epochs': EPOCHS,\n",
        "    'criterion': criterion,\n",
        "    'scaler': scaler,\n",
        "    'device': device,\n",
        "    'k': K,\n",
        "    'test_size': TEST_SIZE,\n",
        "    'patience': PATIENCE,\n",
        "    'verbose': VERBOSE,\n",
        "    'seed': SEED\n",
        "}\n",
        "\n",
        "# Execute search\n",
        "results, best_config, best_score = grid_search_cv(\n",
        "    X=X, y=y,\n",
        "    param_grid=param_grid,\n",
        "    fixed_params=fixed_params,\n",
        "    cv_params=cv_params\n",
        ")"
      ],
      "metadata": {
        "id": "Gb0EwmT1aekZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualise results\n",
        "plot_top_configurations(results, k_splits=K, top_n=5)"
      ],
      "metadata": {
        "id": "cQjdbYHjaeh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🕹️ **Inference**"
      ],
      "metadata": {
        "id": "B5myzy4k-3yK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Configuration 143/432:\n",
        "  batch_size: 16\n",
        "  learning_rate: 0.005\n",
        "  hidden_layers: 1\n",
        "  hidden_size: 512\n",
        "  dropout_rate: 0\n",
        "  l1_lambda: 0.01\n",
        "  l2_lambda: 0.0001\n",
        "  F1 Score: 0.7582±0.0602\n",
        "\"\"\"\n",
        "\n",
        "best_configuration = {}\n",
        "best_configuration['batch_size'] = 16\n",
        "best_configuration['learning_rate'] = 0.005\n",
        "best_configuration['hidden_layers'] = 1\n",
        "best_configuration['hidden_size'] = 512\n",
        "best_configuration['dropout_rate'] = 0\n",
        "best_configuration['l1_lambda'] = 0.01\n",
        "best_configuration['l2_lambda'] = 0.0001"
      ],
      "metadata": {
        "id": "6yKse15QsilR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve the best hyperparameters\n",
        "best_batch_size = best_configuration['batch_size']\n",
        "best_learning_rate = best_configuration['learning_rate']\n",
        "best_hidden_layers = best_configuration['hidden_layers']\n",
        "best_hidden_size = best_configuration['hidden_size']\n",
        "best_dropout_rate = best_configuration['dropout_rate']\n",
        "best_l1_lambda = best_configuration['l1_lambda']\n",
        "best_l2_lambda = best_configuration['l2_lambda']\n",
        "\n",
        "# Initialize lists to store metrics for each split on the test set\n",
        "test_accuracies = []\n",
        "test_precisions = []\n",
        "test_recall_scores = [] # Corrected typo\n",
        "test_f1_scores = []\n",
        "all_test_targets = []\n",
        "all_test_preds = []\n",
        "\n",
        "\n",
        "for split in range(K):\n",
        "    print(f\"Evaluating Split {split+1}/{K}\")\n",
        "\n",
        "    # Regenerate the data splits to ensure the correct test set for this split\n",
        "    X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
        "        X,\n",
        "        y,\n",
        "        test_size=TEST_SIZE,\n",
        "        random_state=SEED+split,\n",
        "        stratify=y\n",
        "    )\n",
        "    # Further split train_val to get train and validation sets (needed for normalization)\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X_train_val,\n",
        "        y_train_val,\n",
        "        test_size=TEST_SIZE,\n",
        "        random_state=SEED+split, # Use same random state for consistent splitting\n",
        "        stratify=y_train_val\n",
        "    )\n",
        "\n",
        "    # Apply the same normalization learned from the training set of this split to the test set\n",
        "    max_df = X_train.max(axis=0)\n",
        "    min_df = X_train.min(axis=0)\n",
        "    # Add a small epsilon to avoid division by zero in case of constant features\n",
        "    X_test_normalized = (X_test - min_df) / (max_df - min_df + 1e-8)\n",
        "\n",
        "\n",
        "    # Create a TensorDataset and DataLoader for the test set\n",
        "    test_ds  = TensorDataset(torch.from_numpy(X_test_normalized), torch.from_numpy(y_test))\n",
        "    test_loader  = make_loader(test_ds, batch_size=best_batch_size, shuffle=False, drop_last=False)\n",
        "\n",
        "    # Initialize the model with the best hyperparameters found\n",
        "    model = FeedForwardNet(in_features=X.shape[1],\n",
        "                           hidden_layers=best_hidden_layers,\n",
        "                           hidden_size=best_hidden_size,\n",
        "                           dropout_rate=best_dropout_rate,\n",
        "                           num_classes=len(np.unique(y))).to(device)\n",
        "\n",
        "    # Construct the path to the saved model weights for this specific split and best configuration\n",
        "    config_name = f\"batch_size_{best_batch_size}_learning_rate_{best_learning_rate}_hidden_layers_{best_hidden_layers}_hidden_size_{best_hidden_size}_dropout_rate_{best_dropout_rate}_l1_lambda_{best_l1_lambda}_l2_lambda_{best_l2_lambda}\"\n",
        "    model_path = f\"models/{config_name}/split_{split}_model.pt\"\n",
        "\n",
        "    # Load the model weights\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.eval() # Set model to evaluation mode\n",
        "\n",
        "\n",
        "    # Make predictions on the test set for this split\n",
        "    split_test_preds, split_test_targets = [], []\n",
        "    with torch.no_grad():  # Disable gradient computation for inference\n",
        "        for xb, yb in test_loader:\n",
        "            xb = xb.to(device)\n",
        "\n",
        "            # Forward pass: get model predictions\n",
        "            logits = model(xb)\n",
        "            preds = logits.argmax(dim=1).cpu().numpy()\n",
        "\n",
        "            # Store batch results\n",
        "            split_test_preds.append(preds)\n",
        "            split_test_targets.append(yb.numpy())\n",
        "\n",
        "    # Combine all batches into single arrays for this split\n",
        "    split_test_preds = np.concatenate(split_test_preds)\n",
        "    split_test_targets = np.concatenate(split_test_targets)\n",
        "\n",
        "    # Calculate metrics for this split's test set\n",
        "    split_test_acc = accuracy_score(split_test_targets, split_test_preds)\n",
        "    split_test_prec = precision_score(split_test_targets, split_test_preds, average='weighted')\n",
        "    split_test_rec = recall_score(split_test_targets, split_test_preds, average='weighted')\n",
        "    split_test_f1 = f1_score(split_test_targets, split_test_preds, average='weighted')\n",
        "\n",
        "    # Print F1 score for the current split\n",
        "    print(f\"  Test F1 Score for Split {split+1}: {split_test_f1:.4f}\")\n",
        "\n",
        "\n",
        "    # Store metrics for calculating average later\n",
        "    test_accuracies.append(split_test_acc)\n",
        "    test_precisions.append(split_test_prec)\n",
        "    test_recall_scores.append(split_test_rec)\n",
        "    test_f1_scores.append(split_test_f1)\n",
        "\n",
        "    # Extend the overall lists for the confusion matrix\n",
        "    all_test_targets.extend(split_test_targets)\n",
        "    all_test_preds.extend(split_test_preds)\n",
        "\n",
        "\n",
        "# Calculate and print average metrics across all splits on the test set\n",
        "print(\"\\nAverage metrics across all splits on the test set:\")\n",
        "print(f\"Mean Accuracy: {np.mean(test_accuracies):.4f} ± {np.std(test_accuracies):.4f}\")\n",
        "print(f\"Mean Precision: {np.mean(test_precisions):.4f} ± {np.std(test_precisions):.4f}\")\n",
        "print(f\"Mean Recall: {np.mean(test_recall_scores):.4f} ± {np.std(test_recall_scores):.4f}\")\n",
        "print(f\"Mean F1 score: {np.mean(test_f1_scores):.4f} ± {np.std(test_f1_scores):.4f}\")\n",
        "\n",
        "\n",
        "# Generate confusion matrix for the concatenated test sets (across all splits)\n",
        "cm = confusion_matrix(all_test_targets, all_test_preds)\n",
        "\n",
        "# Create numeric labels for heatmap annotation\n",
        "labels = np.array([f\"{num}\" for num in cm.flatten()]).reshape(cm.shape)\n",
        "\n",
        "# Visualise confusion matrix\n",
        "plt.figure(figsize=(8, 7))\n",
        "sns.heatmap(cm, annot=labels, fmt='',\n",
        "            cmap='Blues')\n",
        "plt.xlabel('Predicted labels')\n",
        "plt.ylabel('True labels')\n",
        "plt.title('Aggregated Confusion Matrix — Test Sets Across Splits')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RLiotKiDzztT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_models_directory(scores, best_configuration):\n",
        "    \"\"\"\n",
        "    Deletes all model directories and files in the 'models' directory\n",
        "    except for the directory containing the best model based on the\n",
        "    best_configuration.\n",
        "\n",
        "    Args:\n",
        "        scores (dict): Dictionary containing the results of the hyperparameter search.\n",
        "        best_configuration (dict): Dictionary containing the hyperparameters\n",
        "                                   of the best performing configuration.\n",
        "    \"\"\"\n",
        "    models_dir = \"models\"\n",
        "    if not os.path.exists(models_dir):\n",
        "        print(f\"Models directory '{models_dir}' not found.\")\n",
        "        return\n",
        "\n",
        "    # Construct the expected directory name for the best configuration\n",
        "    best_config_dir_name = f\"bs_{best_configuration['batch_size']}_lr_{best_configuration['learning_rate']}_hl_{best_configuration['hidden_layers']}_hs_{best_configuration['hidden_size']}_dr_{best_configuration['dropout_rate']}_l1_{best_configuration['l1_lambda']}_l2_{best_configuration['l2_lambda']}\"\n",
        "    best_config_path = os.path.join(models_dir, best_config_dir_name)\n",
        "\n",
        "    # Add a check to ensure the best configuration directory exists\n",
        "    if not os.path.exists(best_config_path):\n",
        "        print(f\"Error: Best model directory '{best_config_path}' not found. Cannot clean directory safely.\")\n",
        "        return\n",
        "\n",
        "    print(f\"Keeping the best model directory: {best_config_path}\")\n",
        "\n",
        "    # Iterate through all items in the models directory\n",
        "    for item in os.listdir(models_dir):\n",
        "        item_path = os.path.join(models_dir, item)\n",
        "\n",
        "        # If the item is a file or a directory and not the best configuration directory, delete it\n",
        "        if item_path != best_config_path:\n",
        "            if os.path.isdir(item_path):\n",
        "                print(f\"Deleting directory: {item_path}\")\n",
        "                shutil.rmtree(item_path)\n",
        "            elif os.path.isfile(item_path):\n",
        "                print(f\"Deleting file: {item_path}\")\n",
        "                os.remove(item_path)\n",
        "\n",
        "    print(\"Models directory cleaned.\")\n",
        "\n",
        "# clean_models_directory(scores, best_configuration)"
      ],
      "metadata": {
        "id": "IR_JdhGezzvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOZkZVOlzz0e"
      },
      "source": [
        "#  \n",
        "<img src=\"https://airlab.deib.polimi.it/wp-content/uploads/2019/07/airlab-logo-new_cropped.png\" width=\"350\">\n",
        "\n",
        "##### Connect with us:\n",
        "- <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/81/LinkedIn_icon.svg/2048px-LinkedIn_icon.svg.png\" width=\"14\"> **LinkedIn:**  [AIRLab Polimi](https://www.linkedin.com/company/airlab-polimi/)\n",
        "- <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/95/Instagram_logo_2022.svg/800px-Instagram_logo_2022.svg.png\" width=\"14\"> **Instagram:** [airlab_polimi](https://www.instagram.com/airlab_polimi/)\n",
        "\n",
        "##### Contributors:\n",
        "- **Eugenio Lomurno**: eugenio.lomurno@polimi.it\n",
        "- **Alberto Archetti**: alberto.archetti@polimi.it\n",
        "- **Roberto Basla**: roberto.basla@polimi.it\n",
        "- **Carlo Sgaravatti**: carlo.sgaravatti@polimi.it\n",
        "\n",
        "```\n",
        "   Copyright 2025 Eugenio Lomurno, Alberto Archetti, Roberto Basla, Carlo Sgaravatti\n",
        "\n",
        "   Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "   you may not use this file except in compliance with the License.\n",
        "   You may obtain a copy of the License at\n",
        "\n",
        "       http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "   Unless required by applicable law or agreed to in writing, software\n",
        "   distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "   See the License for the specific language governing permissions and\n",
        "   limitations under the License.\n",
        "```\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}